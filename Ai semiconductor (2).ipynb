{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4ab0edd-91c0-42c2-ba02-4aa8ae24a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   # Import Python library for data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606500ef-fbaf-4701-b145-542a50299b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Initial Setup\n",
    "This project begins by importing the pandas library, essential for handling the 420k+ rows of semiconductor stock data \n",
    "from Kaggle[](https://www.kaggle.com/datasets/farukece/semiconductor-stocks-and-the-ai-surge). \n",
    "The goal is to analyze market trends over 2013-2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fcd0fca-82e6-4c1c-b43c-73aeec336007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.ipynb_checkpoints',\n",
       " 'Ai semiconductor.ipynb',\n",
       " 'anaconda_projects',\n",
       " 'cleaned_semi_conductor_se.csv',\n",
       " 'README.md',\n",
       " 'semiconductor_stocks.db',\n",
       " 'semi_conductor_se.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir() # Import os to list files in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cbc86f-748f-4d79-992c-84de9965d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Verify Data Files\n",
    "This step checks the current directory to ensure the dataset file 'semi_conductor_se.csv' is available. \n",
    "This is a critical initial step for loading the 150 companies' data into the analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22cd3964-3a30-4af8-b6b7-f8ec27a1e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('semi_conductor_se.csv')   # Import the dataset for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d464082-25eb-47d9-afaa-cc531a5a0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Load Dataset\n",
    "The dataset is loaded into a pandas DataFrame from 'semi_conductor_se.csv', \n",
    "containing financial metrics (open, close, high, low, volume) for 150 semiconductor companies over 13 years (2012-2025)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cf242ed-533c-48e2-9824-30d9c4f90078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      0\n",
       "company_name    0\n",
       "stock_name      0\n",
       "date            0\n",
       "open            0\n",
       "high            0\n",
       "low             0\n",
       "close           0\n",
       "volume          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()   # Check for missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330ef4b-5578-4a7e-8b39-571b5d21c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Data Quality Check\n",
    "This step verifies the absence of missing values in the dataset, ensuring data integrity for the subsequent analysis of the semiconductor market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37469a4b-8693-4a39-b5ac-82de8369da6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataframe_columns',\n",
       " 'dataframe_hash',\n",
       " 'dtypes_str',\n",
       " 'get_dataframes',\n",
       " 'getpass',\n",
       " 'hashlib',\n",
       " 'import_pandas_safely',\n",
       " 'is_data_frame',\n",
       " 'json',\n",
       " 'os',\n",
       " 'pd']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%who_ls   # %who_ls to check variable names in the namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87bed4-b604-4c66-98e2-82b0b25a1fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Namespace Inspection\n",
    "This command checks the namespace to confirm the DataFrame variable 'df' is correctly assigned, \n",
    "addressing an earlier issue where the variable was not recognized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "234e8672-9acc-426e-b63b-dc14dba5fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('semi_conductor_se.csv')   # Re-import the dataset to assign the variable correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d349dd0-ade7-409d-b614-74dcdd344458",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Variable Assignment Fix\n",
    "Due to a previous namespace issue, the dataset is re-imported to ensure the 'df' variable is properly assigned for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea72e007-5e21-41f7-836f-54b173388988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company_name</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>0.327805</td>\n",
       "      <td>0.330097</td>\n",
       "      <td>0.321157</td>\n",
       "      <td>0.321845</td>\n",
       "      <td>468044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>0.322074</td>\n",
       "      <td>0.326888</td>\n",
       "      <td>0.319094</td>\n",
       "      <td>0.325513</td>\n",
       "      <td>347372000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>0.323908</td>\n",
       "      <td>0.338808</td>\n",
       "      <td>0.322533</td>\n",
       "      <td>0.337204</td>\n",
       "      <td>563548000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>0.336974</td>\n",
       "      <td>0.337204</td>\n",
       "      <td>0.329410</td>\n",
       "      <td>0.333307</td>\n",
       "      <td>533252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>0.333536</td>\n",
       "      <td>0.339725</td>\n",
       "      <td>0.331014</td>\n",
       "      <td>0.333307</td>\n",
       "      <td>508244000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 company_name stock_name        date      open      high  \\\n",
       "0           0       NVIDIA       NVDA  2012-01-03  0.327805  0.330097   \n",
       "1           1       NVIDIA       NVDA  2012-01-04  0.322074  0.326888   \n",
       "2           2       NVIDIA       NVDA  2012-01-05  0.323908  0.338808   \n",
       "3           3       NVIDIA       NVDA  2012-01-06  0.336974  0.337204   \n",
       "4           4       NVIDIA       NVDA  2012-01-09  0.333536  0.339725   \n",
       "\n",
       "        low     close     volume  \n",
       "0  0.321157  0.321845  468044000  \n",
       "1  0.319094  0.325513  347372000  \n",
       "2  0.322533  0.337204  563548000  \n",
       "3  0.329410  0.333307  533252000  \n",
       "4  0.331014  0.333307  508244000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()  # Check the success of the table import; if the first rows appear, everything is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34719aa4-48d7-4a10-aed2-4beab31386b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      0\n",
       "company_name    0\n",
       "stock_name      0\n",
       "date            0\n",
       "open            0\n",
       "high            0\n",
       "low             0\n",
       "close           0\n",
       "volume          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()   # Check for missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81e0bebf-c702-4817-8265-0f9d6226131a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422729 entries, 0 to 422728\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Unnamed: 0    422729 non-null  int64  \n",
      " 1   company_name  422729 non-null  object \n",
      " 2   stock_name    422729 non-null  object \n",
      " 3   date          422729 non-null  object \n",
      " 4   open          422729 non-null  float64\n",
      " 5   high          422729 non-null  float64\n",
      " 6   low           422729 non-null  float64\n",
      " 7   close         422729 non-null  float64\n",
      " 8   volume        422729 non-null  int64  \n",
      "dtypes: float64(4), int64(2), object(3)\n",
      "memory usage: 29.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()    # Display general information about the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f10b6db2-628a-427b-b343-2c3d85dc44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])   # Convert 'date' column to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25db2ec-6036-421d-bed4-fb63b9ac5a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Date Conversion\n",
    "This step converts the 'date' column from text to datetime format, enabling time-series analysis for the 420k+ rows of semiconductor stock data \n",
    "from 2012-2025. \n",
    "This is a key preparation for trend analysis in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddd05876-6cfe-4e59-9778-076979330acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)   # Видаляємо дублікати рядків в таблиці"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cb2d376-14a4-490d-8e43-aa8af03c7091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company_name</th>\n",
       "      <th>stock_name</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>0.327805</td>\n",
       "      <td>0.330097</td>\n",
       "      <td>0.321157</td>\n",
       "      <td>0.321845</td>\n",
       "      <td>468044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>0.322074</td>\n",
       "      <td>0.326888</td>\n",
       "      <td>0.319094</td>\n",
       "      <td>0.325513</td>\n",
       "      <td>347372000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>0.323908</td>\n",
       "      <td>0.338808</td>\n",
       "      <td>0.322533</td>\n",
       "      <td>0.337204</td>\n",
       "      <td>563548000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>0.336974</td>\n",
       "      <td>0.337204</td>\n",
       "      <td>0.329410</td>\n",
       "      <td>0.333307</td>\n",
       "      <td>533252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>0.333536</td>\n",
       "      <td>0.339725</td>\n",
       "      <td>0.331014</td>\n",
       "      <td>0.333307</td>\n",
       "      <td>508244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422724</th>\n",
       "      <td>422724</td>\n",
       "      <td>Kalray</td>\n",
       "      <td>ALKAL.PA</td>\n",
       "      <td>2025-07-28</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.661000</td>\n",
       "      <td>84650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422725</th>\n",
       "      <td>422725</td>\n",
       "      <td>Kalray</td>\n",
       "      <td>ALKAL.PA</td>\n",
       "      <td>2025-07-29</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>96811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422726</th>\n",
       "      <td>422726</td>\n",
       "      <td>Kalray</td>\n",
       "      <td>ALKAL.PA</td>\n",
       "      <td>2025-07-30</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.671000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>175991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422727</th>\n",
       "      <td>422727</td>\n",
       "      <td>Kalray</td>\n",
       "      <td>ALKAL.PA</td>\n",
       "      <td>2025-07-31</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>0.688000</td>\n",
       "      <td>77266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422728</th>\n",
       "      <td>422728</td>\n",
       "      <td>Kalray</td>\n",
       "      <td>ALKAL.PA</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>91221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422729 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 company_name stock_name       date      open      high  \\\n",
       "0                0       NVIDIA       NVDA 2012-01-03  0.327805  0.330097   \n",
       "1                1       NVIDIA       NVDA 2012-01-04  0.322074  0.326888   \n",
       "2                2       NVIDIA       NVDA 2012-01-05  0.323908  0.338808   \n",
       "3                3       NVIDIA       NVDA 2012-01-06  0.336974  0.337204   \n",
       "4                4       NVIDIA       NVDA 2012-01-09  0.333536  0.339725   \n",
       "...            ...          ...        ...        ...       ...       ...   \n",
       "422724      422724       Kalray   ALKAL.PA 2025-07-28  0.660000  0.686000   \n",
       "422725      422725       Kalray   ALKAL.PA 2025-07-29  0.670000  0.695000   \n",
       "422726      422726       Kalray   ALKAL.PA 2025-07-30  0.695000  0.760000   \n",
       "422727      422727       Kalray   ALKAL.PA 2025-07-31  0.700000  0.730000   \n",
       "422728      422728       Kalray   ALKAL.PA 2025-08-01  0.684000  0.684000   \n",
       "\n",
       "             low     close     volume  \n",
       "0       0.321157  0.321845  468044000  \n",
       "1       0.319094  0.325513  347372000  \n",
       "2       0.322533  0.337204  563548000  \n",
       "3       0.329410  0.333307  533252000  \n",
       "4       0.331014  0.333307  508244000  \n",
       "...          ...       ...        ...  \n",
       "422724  0.644000  0.661000      84650  \n",
       "422725  0.670000  0.690000      96811  \n",
       "422726  0.671000  0.700000     175991  \n",
       "422727  0.679000  0.688000      77266  \n",
       "422728  0.620000  0.620000      91221  \n",
       "\n",
       "[422729 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()   # Очищаємо таблицю від пропусків"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b49c135-b39f-469f-9e9e-3ceb3a9dbb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_semi_conductor_se.csv', index=False)   # Оновлюємо та зберігаємо нову таблицю для подальшого імпорту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cbd1db7-1659-4353-a356-189d7baf5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 # Імпортуємо бібліотеку для роботи з SQL\n",
    "\n",
    "conn = sqlite3.connect('semiconductor_stocks.db') # Створюємо файл бази даних\n",
    "df.to_sql('stocks', conn, if_exists='replace', index=True) # Записуємо DataFrame у таблицю\n",
    "conn.close() # Закриваємо з'єднання"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9c1b404-c82a-4322-8ddd-13b23833ac48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 company_name stock_name        date      open      high  \\\n",
      "0           0       NVIDIA       NVDA  2012-01-03  0.327805  0.330097   \n",
      "1           1       NVIDIA       NVDA  2012-01-04  0.322074  0.326888   \n",
      "2           2       NVIDIA       NVDA  2012-01-05  0.323908  0.338808   \n",
      "3           3       NVIDIA       NVDA  2012-01-06  0.336974  0.337204   \n",
      "4           4       NVIDIA       NVDA  2012-01-09  0.333536  0.339725   \n",
      "\n",
      "        low     close     volume  \n",
      "0  0.321157  0.321845  468044000  \n",
      "1  0.319094  0.325513  347372000  \n",
      "2  0.322533  0.337204  563548000  \n",
      "3  0.329410  0.333307  533252000  \n",
      "4  0.331014  0.333307  508244000  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "744afc45-b474-41ef-b329-e52eb556a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bb6eef9-7228-4953-a4cf-cb9e5e60c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_semi_conductor_se.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f529731f-ff08-46ad-b4a4-4981bed057ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 company_name stock_name        date      open      high  \\\n",
      "0           0       NVIDIA       NVDA  2012-01-03  0.327805  0.330097   \n",
      "1           1       NVIDIA       NVDA  2012-01-04  0.322074  0.326888   \n",
      "2           2       NVIDIA       NVDA  2012-01-05  0.323908  0.338808   \n",
      "3           3       NVIDIA       NVDA  2012-01-06  0.336974  0.337204   \n",
      "4           4       NVIDIA       NVDA  2012-01-09  0.333536  0.339725   \n",
      "\n",
      "        low     close     volume  \n",
      "0  0.321157  0.321845  468044000  \n",
      "1  0.319094  0.325513  347372000  \n",
      "2  0.322533  0.337204  563548000  \n",
      "3  0.329410  0.333307  533252000  \n",
      "4  0.331014  0.333307  508244000  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35c7b170-7f77-46c0-a052-08c9971123d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422729 entries, 0 to 422728\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Unnamed: 0    422729 non-null  int64  \n",
      " 1   company_name  422729 non-null  object \n",
      " 2   stock_name    422729 non-null  object \n",
      " 3   date          422729 non-null  object \n",
      " 4   open          422729 non-null  float64\n",
      " 5   high          422729 non-null  float64\n",
      " 6   low           422729 non-null  float64\n",
      " 7   close         422729 non-null  float64\n",
      " 8   volume        422729 non-null  int64  \n",
      "dtypes: float64(4), int64(2), object(3)\n",
      "memory usage: 29.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16899dbe-d04e-439b-826d-a823191e88ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5006e4c-f6b5-4bcf-8eba-c4beb5574c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422729 entries, 0 to 422728\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   Unnamed: 0    422729 non-null  int64         \n",
      " 1   company_name  422729 non-null  object        \n",
      " 2   stock_name    422729 non-null  object        \n",
      " 3   date          422729 non-null  datetime64[ns]\n",
      " 4   open          422729 non-null  float64       \n",
      " 5   high          422729 non-null  float64       \n",
      " 6   low           422729 non-null  float64       \n",
      " 7   close         422729 non-null  float64       \n",
      " 8   volume        422729 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(2), object(2)\n",
      "memory usage: 29.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1e54c6c-bb8f-4930-b978-50edb3d2f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04c01615-3082-4f4b-ac8c-1d23b3e5b50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дані успішно завантажено в MySQL!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import mysql.connector # Ця бібліотека є частиною connector-python\n",
    "import urllib.parse \n",
    "user = 'root'\n",
    "password = 'пароль'\n",
    "host = 'localhost' \n",
    "database = 'ai_semiconductor'\n",
    "# Кодуємо пароль, щоб спеціальні символи не спричиняли помилок\n",
    "encoded_password = urllib.parse.quote_plus(password)\n",
    "\n",
    "# Створення рушія з'єднання з закодованим паролем\n",
    "engine = create_engine(f'mysql+mysqlconnector://{user}:{encoded_password}@{host}/{database}')\n",
    "\n",
    "# Завантаження даних у MySQL\n",
    "df.to_sql('cleaned_semi_conductor_se', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Дані успішно завантажено в MySQL!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4274b4d5-2d89-4f2c-85a4-ca34e2791085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Припустимо, ти завантажила дані з файлу cleaned_company_info.csv\n",
    "# Найчастіше допомагає кодування 'cp1252' або 'latin1'\n",
    "df_company_info = pd.read_csv('Company info (semi_conductor_se).csv', sep=';', encoding='cp1252')\n",
    "\n",
    "\n",
    "# Тепер використовуй цю нову, правильну назву для всіх операцій\n",
    "df_company_info['Competitor_List'] = df_company_info['Competitors'].str.split(';')\n",
    "df_company_info['Competitor_List'] = df_company_info['Competitor_List'].apply(lambda x: [item.strip() for item in x] if isinstance(x, list) else [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c60b2bdc-7a3e-4ad4-83f1-b642d2f69ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Company_name', 'Symbol', 'Activity_Sphere', 'Tech_Subcategory',\n",
      "       'Core_Technology', 'Growth_Outlook', 'Market_Cap_Tier', 'Competitors',\n",
      "       'Competitor_List'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_company_info.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9f93a04-204c-4a51-9799-75e8c8c73f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Company_name                                    Competitor_List\n",
      "0               Xperi   [Applied Materials, Lam Research, KLA, Entegris]\n",
      "1               X-FAB  [Tower Semiconductor, Littelfuse, GlobalFoundr...\n",
      "2           Wolfspeed  [Infineon Technologies, ON Semiconductor, Rohm...\n",
      "3  WIN Semiconductors  [Global Communication Semiconductors (GCS Hold...\n",
      "4         Weebit Nano  [4DS Memory, BrainChip,  Phase Change Memory, ...\n"
     ]
    }
   ],
   "source": [
    "print(df_company_info[['Company_name', 'Competitor_List']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c358f4e5-c0ba-4515-bed6-9b2d6955f211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Company_name', 'Symbol', 'Activity_Sphere', 'Tech_Subcategory',\n",
      "       'Core_Technology', 'Growth_Outlook', 'Market_Cap_Tier', 'Competitors',\n",
      "       'Competitor_List'],\n",
      "      dtype='object')\n",
      "         Company_name                                    Competitor_List\n",
      "0               Xperi  [Applied Materials,  Lam Research,  KLA,  Ente...\n",
      "1               X-FAB  [Tower Semiconductor,  Littelfuse,  GlobalFoun...\n",
      "2           Wolfspeed  [Infineon Technologies,  ON Semiconductor,  Ro...\n",
      "3  WIN Semiconductors  [Global Communication Semiconductors (GCS Hold...\n",
      "4         Weebit Nano  [4DS Memory,  BrainChip,   Phase Change Memory...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Завантажуємо ваш DataFrame, вказуючи роздільник і кодування\n",
    "df_company_info = pd.read_csv('Company info (semi_conductor_se).csv', sep=';', encoding='cp1252')\n",
    "\n",
    "# Створюємо нову колонку, використовуючи простий метод\n",
    "df_company_info['Competitor_List'] = df_company_info['Competitors'].str.split(',')\n",
    "\n",
    "# Перевіряємо, що нова колонка тепер є\n",
    "print(df_company_info.columns)\n",
    "print(df_company_info[['Company_name', 'Competitor_List']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd743c3e-cc00-4369-b5f8-74fce0317f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Company_name                                    Competitor_List\n",
      "0                 Xperi  [Applied Materials,  Lam Research,  KLA,  Ente...\n",
      "1                 X-FAB  [Tower Semiconductor,  Littelfuse,  GlobalFoun...\n",
      "2             Wolfspeed  [Infineon Technologies,  ON Semiconductor,  Ro...\n",
      "3    WIN Semiconductors  [Global Communication Semiconductors (GCS Hold...\n",
      "4           Weebit Nano  [4DS Memory,  BrainChip,   Phase Change Memory...\n",
      "..                  ...                                                ...\n",
      "149   Aehr Test Systems                     [Teradyne,  Cohu,  FormFactor]\n",
      "150           Advantest                 [Teradyne,  Cohu,  Tokyo Electron]\n",
      "151        ACM Research           [Lam Research,  Applied Materials,  KLA]\n",
      "152                 NaN                                                NaN\n",
      "153                 NaN                                                NaN\n",
      "\n",
      "[154 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_company_info[['Company_name', 'Competitor_List']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9425e440-7426-41c8-9a89-3cc04224d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Припустимо, що ваш список називається 'competitor_list'\n",
    "df_competitors = pd.DataFrame(['Competitor_List'], columns=['Competitor_Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17e7192e-05e0-4f14-89a9-d48bb60984b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xdc in position 8199: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmysql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnector\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompany info (semi_conductor_se).csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Налаштування підключення.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Змініть лише текст у лапках на свої реальні дані.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m user \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:663\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\codecs.py:325\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[0;32m    324\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m--> 325\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_decode(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors, final)\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xdc in position 8199: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import mysql.connector\n",
    "import urllib.parse\n",
    "\n",
    "df = pd.read_csv('Company info (semi_conductor_se).csv')\n",
    "\n",
    "# Налаштування підключення.\n",
    "# Змініть лише текст у лапках на свої реальні дані.\n",
    "user = 'root'\n",
    "password = 'UN4%39,h2r#k'\n",
    "host = 'localhost'\n",
    "database = 'ai_semiconductor'\n",
    "\n",
    "# Кодуємо пароль, щоб кома та інші символи не спричиняли помилок\n",
    "encoded_password = urllib.parse.quote_plus(password)\n",
    "\n",
    "# Створення рушія з'єднання з закодованим паролем\n",
    "engine = create_engine(f'mysql+mysqlconnector://{user}:{encoded_password}@{host}/{database}')\n",
    "\n",
    "# Завантаження даних у MySQL\n",
    "df.to_sql('cleaned_semi_conductor_se', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Дані успішно завантажено в MySQL!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "184158d0-8e5b-4c9d-a08e-f81a921dca02",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 11 fields in line 3, saw 16\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompany info (semi_conductor_se).csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 8\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mФайл успішно завантажено з кодуванням \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 11 fields in line 3, saw 16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_companies = pd.read_csv('Company info (semi_conductor_se).csv', sep=';', quotechar='\"', encoding='cp1252')\n",
    "\n",
    "file_path = 'Company info (semi_conductor_se).csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    print(\"Файл успішно завантажено з кодуванням 'utf-8'.\")\n",
    "except UnicodeDecodeError:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='cp1252')\n",
    "        print(\"Файл успішно завантажено з кодуванням 'cp1252'.\")\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='latin1')\n",
    "            print(\"Файл успішно завантажено з кодуванням 'latin1'.\")\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"Не вдалося завантажити файл. Спробуйте інше кодування.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49d6a939-c4ce-45e8-a5d5-1aae998c80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_company_info = pd.read_csv(\n",
    "    'Company info (semi_conductor_se).csv',\n",
    "    sep=';',\n",
    "    encoding='cp1252'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b89e23-490c-4392-be06-2537d911b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_company_info = pd.read_csv('Company info (semi_conductor_se).csv', sep=';', quotechar='\"', encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c141c87-5768-4172-b7e9-4db496ad28c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 154 entries, 0 to 153\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Company_name      152 non-null    object\n",
      " 1   Symbol            152 non-null    object\n",
      " 2   Activity_Sphere   152 non-null    object\n",
      " 3   Tech_Subcategory  152 non-null    object\n",
      " 4   Core_Technology   152 non-null    object\n",
      " 5   Growth_Outlook    152 non-null    object\n",
      " 6   Market_Cap_Tier   152 non-null    object\n",
      " 7   Competitors       152 non-null    object\n",
      "dtypes: object(8)\n",
      "memory usage: 9.8+ KB\n",
      "None\n",
      "         Company_name    Symbol  \\\n",
      "0               Xperi      XPER   \n",
      "1               X-FAB      XFAB   \n",
      "2           Wolfspeed      WOLF   \n",
      "3  WIN Semiconductors  3105.TWO   \n",
      "4         Weebit Nano       WBT   \n",
      "\n",
      "                                     Activity_Sphere  \\\n",
      "0     Consumer Tech, Media & Entertainment Licensing   \n",
      "1     Semiconductor Foundry, Analog/Mixed-Signal ICs   \n",
      "2    Semiconductor Manufacturing, Power & RF Devices   \n",
      "3  Semiconductor Manufacturing, Specialty Foundry...   \n",
      "4      Semiconductor Memory Technology, IP Licensing   \n",
      "\n",
      "                                    Tech_Subcategory  \\\n",
      "0  Audio (DTS), Smart TV (TiVo OS), Automotive (D...   \n",
      "1  CMOS, SOI, MEMS, SiC (Silicon Carbide), High-V...   \n",
      "2       Silicon Carbide (SiC), Gallium Nitride (GaN)   \n",
      "3     GaAs (Gallium Arsenide), GaN (Gallium Nitride)   \n",
      "4   Resistive RAM (ReRAM), Non-Volatile Memory (NVM)   \n",
      "\n",
      "                                     Core_Technology  \\\n",
      "0  IP Licensing, Audio (DTS), Smart TV Platforms ...   \n",
      "1  Wafer Fabrication, Specialty Foundry Services,...   \n",
      "2  Wide-bandgap semiconductors (SiC & GaN) for po...   \n",
      "3  Pure-play foundry services for GaAs and GaN wa...   \n",
      "4  Next-generation, fab-friendly non-volatile mem...   \n",
      "\n",
      "                                      Growth_Outlook        Market_Cap_Tier  \\\n",
      "0   Cautious outlook (product-specific growth: Ti...              Small-Cap   \n",
      "1  Long-term growth (demand from automotive, indu...                Mid-Cap   \n",
      "2  Long-term growth (demand from EV & renewable e...                Mid-Cap   \n",
      "3  Long-term growth (demand from next-gen wireles...                Mid-Cap   \n",
      "4  Long-term growth (breakout phase driven by com...  Micro-Cap / Small-Cap   \n",
      "\n",
      "                                         Competitors  \n",
      "0    Applied Materials, Lam Research, KLA, Entegris   \n",
      "1  Tower Semiconductor, Littelfuse, GlobalFoundri...  \n",
      "2  Infineon Technologies, ON Semiconductor, Rohm ...  \n",
      "3  Global Communication Semiconductors (GCS Holdi...  \n",
      "4  4DS Memory, BrainChip,  Phase Change Memory, M...  \n"
     ]
    }
   ],
   "source": [
    "print(df_company_info.info())\n",
    "print(df_company_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4a77ccc-cd51-49b4-9775-4929ec625922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company_info['Competitor_List'] = df_company_info['Competitors'].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76694cfb-e34c-4a5b-86ac-8c23b2e42fab",
   "metadata": {},
   "outputs": [
    {
     "ename": "InterfaceError",
     "evalue": "(mysql.connector.errors.InterfaceError) Failed executing the operation; Python type list cannot be converted\n[SQL: INSERT INTO company_info_with_competitors (`Company_name`, `Symbol`, `Activity_Sphere`, `Tech_Subcategory`, `Core_Technology`, `Growth_Outlook`, `Market_Cap_Tier`, `Competitors`, `Competitor_List`) VALUES (%(Company_name)s, %(Symbol)s, %(Activity_Sphere)s, %(Tech_Subcategory)s, %(Core_Technology)s, %(Growth_Outlook)s, %(Market_Cap_Tier)s, %(Competitors)s, %(Competitor_List)s)]\n[parameters: [{'Company_name': 'Xperi', 'Symbol': 'XPER', 'Activity_Sphere': 'Consumer Tech, Media & Entertainment Licensing', 'Tech_Subcategory': 'Audio (DTS), Smart TV (TiVo OS), Automotive (DTS AutoStage), Semiconductor IP', 'Core_Technology': 'IP Licensing, Audio (DTS), Smart TV Platforms (TiVo), Automotive Media', 'Growth_Outlook': ' Cautious outlook (product-specific growth: TiVo OS & DTS AutoStage)', 'Market_Cap_Tier': 'Small-Cap', 'Competitors': 'Applied Materials, Lam Research, KLA, Entegris ', 'Competitor_List': ['Applied Materials', ' Lam Research', ' KLA', ' Entegris ']}, {'Company_name': 'X-FAB', 'Symbol': 'XFAB', 'Activity_Sphere': 'Semiconductor Foundry, Analog/Mixed-Signal ICs', 'Tech_Subcategory': 'CMOS, SOI, MEMS, SiC (Silicon Carbide), High-Voltage', 'Core_Technology': 'Wafer Fabrication, Specialty Foundry Services, Analog/Mixed-Signal Circuits', 'Growth_Outlook': 'Long-term growth (demand from automotive, industrial, and medical markets), with short-term headwinds', 'Market_Cap_Tier': 'Mid-Cap', 'Competitors': 'Tower Semiconductor, Littelfuse, GlobalFoundries, Analog Devices, STMicroelectronics, ON Semiconductor', 'Competitor_List': ['Tower Semiconductor', ' Littelfuse', ' GlobalFoundries', ' Analog Devices', ' STMicroelectronics', ' ON Semiconductor']}, {'Company_name': 'Wolfspeed', 'Symbol': 'WOLF', 'Activity_Sphere': 'Semiconductor Manufacturing, Power & RF Devices', 'Tech_Subcategory': 'Silicon Carbide (SiC), Gallium Nitride (GaN)', 'Core_Technology': 'Wide-bandgap semiconductors (SiC & GaN) for power devices and radio frequency (RF) applications.', 'Growth_Outlook': 'Long-term growth (demand from EV & renewable energy markets), with short-term headwinds', 'Market_Cap_Tier': 'Mid-Cap', 'Competitors': 'Infineon Technologies, ON Semiconductor, Rohm Co., Ltd., STMicroelectronics (in SiC segment); Qorvo, Inc., NXP Semiconductors (in RF segment)', 'Competitor_List': ['Infineon Technologies', ' ON Semiconductor', ' Rohm Co.', ' Ltd.', ' STMicroelectronics (in SiC segment); Qorvo', ' Inc.', ' NXP Semiconductors (in RF segment)']}, {'Company_name': 'WIN Semiconductors', 'Symbol': '3105.TWO', 'Activity_Sphere': 'Semiconductor Manufacturing, Specialty Foundry Services', 'Tech_Subcategory': 'GaAs (Gallium Arsenide), GaN (Gallium Nitride)', 'Core_Technology': 'Pure-play foundry services for GaAs and GaN wafers, focusing on RF and microwave applications.', 'Growth_Outlook': 'Long-term growth (demand from next-gen wireless, LEO satellites and IoT trends), with short-term headwinds', 'Market_Cap_Tier': 'Mid-Cap', 'Competitors': 'Global Communication Semiconductors (GCS Holdings), Advanced Wireless Semiconductor Co.', 'Competitor_List': ['Global Communication Semiconductors (GCS Holdings)', ' Advanced Wireless Semiconductor Co.']}, {'Company_name': 'Weebit Nano', 'Symbol': 'WBT', 'Activity_Sphere': 'Semiconductor Memory Technology, IP Licensing', 'Tech_Subcategory': 'Resistive RAM (ReRAM), Non-Volatile Memory (NVM)', 'Core_Technology': 'Next-generation, fab-friendly non-volatile memory (ReRAM) that is faster, more energy-efficient and scalable than traditional flash memory.', 'Growth_Outlook': 'Long-term growth (breakout phase driven by commercialization and partnerships in AI, automotive & IoT), with short-term headwinds (lack of significant revenue & profitability, and execution risk).', 'Market_Cap_Tier': 'Micro-Cap / Small-Cap', 'Competitors': '4DS Memory, BrainChip,  Phase Change Memory, MRAM.', 'Competitor_List': ['4DS Memory', ' BrainChip', '  Phase Change Memory', ' MRAM.']}, {'Company_name': 'Vishay Intertechnology', 'Symbol': 'VSH', 'Activity_Sphere': 'Semiconductor Manufacturing, Passive Electronic Components', 'Tech_Subcategory': 'Discrete semiconductors (MOSFETs, diodes, optoelectronics), passive components (resistors, capacitors, inductors)', 'Core_Technology': 'Manufacturing a broad range of discrete semiconductors and passive electronic components for mission-critical applications.', 'Growth_Outlook': 'Cautious outlook with long-term potential (expansion of manufacturing capacity, demand from EV, 5G, and renewable energy markets)', 'Market_Cap_Tier': 'Mid-Cap', 'Competitors': 'Infineon, ON Semiconductor, TDK-EPCOS, Murata, Yageo, Kyocera, Diodes Inc.', 'Competitor_List': ['Infineon', ' ON Semiconductor', ' TDK-EPCOS', ' Murata', ' Yageo', ' Kyocera', ' Diodes Inc.']}, {'Company_name': 'VisEra Technologies', 'Symbol': '6789', 'Activity_Sphere': 'Semiconductor Manufacturing, Foundry Services', 'Tech_Subcategory': 'Image Sensors, Optical Components, Wafer-Level Packaging (Color Filters, Micro-Lenses)', 'Core_Technology': 'Specialized foundry services for optical devices and sensors used in mobile phones, automotive, AR/VR, and other devices.', 'Growth_Outlook': 'Cautious outlook with long-term potential (demand for image sensors and optical components, especially in the mobile and automotive segments)', 'Market_Cap_Tier': 'Small-Cap', 'Competitors': 'Samsung, OmniVision, ', 'Competitor_List': ['Samsung', ' OmniVision', ' ']}, {'Company_name': 'VeriSilicon Microelectronics', 'Symbol': '688521', 'Activity_Sphere': 'Semiconductor Design IP & Custom Silicon Solutions', 'Tech_Subcategory': 'Processor IP (GPU, NPU, VPU), IoT Connectivity, Analog & Mixed-Signal IP', 'Core_Technology': 'A platform-based, comprehensive IP portfolio and custom turnkey silicon design services. VeriSilicon provides a one-stop-shop for customers to develop their own chips.', 'Growth_Outlook': 'Strong growth potential (rapid expansion of the global semiconductor IP market, particularly in AI, IoT, and automotive sectors)', 'Market_Cap_Tier': 'Mid-Cap', 'Competitors': 'ARM Holdings, Synopsys, Cadence Design Systems, Imagination Technologies, Ceva.', 'Competitor_List': ['ARM Holdings', ' Synopsys', ' Cadence Design Systems', ' Imagination Technologies', ' Ceva.']}  ... displaying 10 of 154 total bound parameter sets ...  {'Company_name': None, 'Symbol': None, 'Activity_Sphere': None, 'Tech_Subcategory': None, 'Core_Technology': None, 'Growth_Outlook': None, 'Market_Cap_Tier': None, 'Competitors': None, 'Competitor_List': None}, {'Company_name': None, 'Symbol': None, 'Activity_Sphere': None, 'Tech_Subcategory': None, 'Core_Technology': None, 'Growth_Outlook': None, 'Market_Cap_Tier': None, 'Competitors': None, 'Competitor_List': None}]]\n(Background on this error at: https://sqlalche.me/e/20/rvf5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1933\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1933\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_executemany(\n\u001b[0;32m   1934\u001b[0m             cursor,\n\u001b[0;32m   1935\u001b[0m             str_statement,\n\u001b[0;32m   1936\u001b[0m             effective_parameters,\n\u001b[0;32m   1937\u001b[0m             context,\n\u001b[0;32m   1938\u001b[0m         )\n\u001b[0;32m   1939\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m effective_parameters \u001b[38;5;129;01mand\u001b[39;00m context\u001b[38;5;241m.\u001b[39mno_parameters:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:939\u001b[0m, in \u001b[0;36mDefaultDialect.do_executemany\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdo_executemany\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 939\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecutemany(statement, parameters)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mysql\\connector\\cursor_cext.py:470\u001b[0m, in \u001b[0;36mCMySQLCursor.executemany\u001b[1;34m(self, operation, seq_params)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 470\u001b[0m stmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_insert(operation, seq_params)\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stmt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mysql\\connector\\cursor_cext.py:424\u001b[0m, in \u001b[0;36mCMySQLCursor._batch_insert\u001b[1;34m(self, operation, seq_params)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InterfaceError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed executing the operation; \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInterfaceError\u001b[0m: Failed executing the operation; Python type list cannot be converted",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_engine(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmysql+mysqlconnector://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoded_password\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatabase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 4. Запишіть DataFrame в базу даних (якщо вона існує, вона буде замінена)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m df_company_info\u001b[38;5;241m.\u001b[39mto_sql(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany_info_with_competitors\u001b[39m\u001b[38;5;124m'\u001b[39m, engine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mДані з колонкою \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompetitor_List\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m успішно завантажено в MySQL!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3087\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2889\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2890\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2891\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3083\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3085\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[0;32m   3088\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3089\u001b[0m     name,\n\u001b[0;32m   3090\u001b[0m     con,\n\u001b[0;32m   3091\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m   3092\u001b[0m     if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[0;32m   3093\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   3094\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3095\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3096\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   3097\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   3098\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:842\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    839\u001b[0m     )\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[0;32m    843\u001b[0m         frame,\n\u001b[0;32m    844\u001b[0m         name,\n\u001b[0;32m    845\u001b[0m         if_exists\u001b[38;5;241m=\u001b[39mif_exists,\n\u001b[0;32m    846\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m    847\u001b[0m         index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m    848\u001b[0m         schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m    849\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    850\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    851\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    852\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    853\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m    854\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:2018\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   2006\u001b[0m sql_engine \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m   2008\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_table(\n\u001b[0;32m   2009\u001b[0m     frame\u001b[38;5;241m=\u001b[39mframe,\n\u001b[0;32m   2010\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2015\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   2016\u001b[0m )\n\u001b[1;32m-> 2018\u001b[0m total_inserted \u001b[38;5;241m=\u001b[39m sql_engine\u001b[38;5;241m.\u001b[39minsert_records(\n\u001b[0;32m   2019\u001b[0m     table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m   2020\u001b[0m     con\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon,\n\u001b[0;32m   2021\u001b[0m     frame\u001b[38;5;241m=\u001b[39mframe,\n\u001b[0;32m   2022\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   2023\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   2024\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[0;32m   2025\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   2026\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   2027\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m   2028\u001b[0m )\n\u001b[0;32m   2030\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_case_sensitive(name\u001b[38;5;241m=\u001b[39mname, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[0;32m   2031\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_inserted\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:1567\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(msg, err_text):\n\u001b[0;32m   1566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf cannot be used with MySQL\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m-> 1567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:1558\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[1;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1555\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m exc\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39minsert(chunksize\u001b[38;5;241m=\u001b[39mchunksize, method\u001b[38;5;241m=\u001b[39mmethod)\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mStatementError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1560\u001b[0m     \u001b[38;5;66;03m# GH34431\u001b[39;00m\n\u001b[0;32m   1561\u001b[0m     \u001b[38;5;66;03m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[0;32m   1562\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m(1054, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf(e0)?\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield list\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m))(?#\u001b[39m\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;124m    )|inf can not be used with MySQL\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:1119\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[1;34m(self, chunksize, method)\u001b[0m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m chunk_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[1;32m-> 1119\u001b[0m num_inserted \u001b[38;5;241m=\u001b[39m exec_insert(conn, keys, chunk_iter)\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_inserted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py:1010\u001b[0m, in \u001b[0;36mSQLTable._execute_insert\u001b[1;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;124;03mExecute SQL statement inserting data\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m   Each item contains a list of values to be inserted\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, row)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data_iter]\n\u001b[1;32m-> 1010\u001b[0m result \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable\u001b[38;5;241m.\u001b[39minsert(), data)\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1416\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m meth(\n\u001b[0;32m   1417\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1418\u001b[0m         distilled_parameters,\n\u001b[0;32m   1419\u001b[0m         execution_options \u001b[38;5;129;01mor\u001b[39;00m NO_OPTIONS,\n\u001b[0;32m   1420\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:523\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[1;32m--> 523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\u001b[38;5;241m.\u001b[39m_execute_clauseelement(\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m, distilled_params, execution_options\n\u001b[0;32m    525\u001b[0m     )\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1638\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1626\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1627\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[0;32m   1628\u001b[0m )\n\u001b[0;32m   1630\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1631\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[0;32m   1632\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1636\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1637\u001b[0m )\n\u001b[1;32m-> 1638\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_context(\n\u001b[0;32m   1639\u001b[0m     dialect,\n\u001b[0;32m   1640\u001b[0m     dialect\u001b[38;5;241m.\u001b[39mexecution_ctx_cls\u001b[38;5;241m.\u001b[39m_init_compiled,\n\u001b[0;32m   1641\u001b[0m     compiled_sql,\n\u001b[0;32m   1642\u001b[0m     distilled_parameters,\n\u001b[0;32m   1643\u001b[0m     execution_options,\n\u001b[0;32m   1644\u001b[0m     compiled_sql,\n\u001b[0;32m   1645\u001b[0m     distilled_parameters,\n\u001b[0;32m   1646\u001b[0m     elem,\n\u001b[0;32m   1647\u001b[0m     extracted_params,\n\u001b[0;32m   1648\u001b[0m     cache_hit\u001b[38;5;241m=\u001b[39mcache_hit,\n\u001b[0;32m   1649\u001b[0m )\n\u001b[0;32m   1650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[0;32m   1652\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1653\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1657\u001b[0m         ret,\n\u001b[0;32m   1658\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1843\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[0;32m   1842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_single_context(\n\u001b[0;32m   1844\u001b[0m         dialect, context, statement, parameters\n\u001b[0;32m   1845\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1983\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1980\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[0;32m   1982\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1983\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(\n\u001b[0;32m   1984\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[0;32m   1985\u001b[0m     )\n\u001b[0;32m   1987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2352\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2350\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2351\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2354\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1933\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1931\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1933\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_executemany(\n\u001b[0;32m   1934\u001b[0m             cursor,\n\u001b[0;32m   1935\u001b[0m             str_statement,\n\u001b[0;32m   1936\u001b[0m             effective_parameters,\n\u001b[0;32m   1937\u001b[0m             context,\n\u001b[0;32m   1938\u001b[0m         )\n\u001b[0;32m   1939\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m effective_parameters \u001b[38;5;129;01mand\u001b[39;00m context\u001b[38;5;241m.\u001b[39mno_parameters:\n\u001b[0;32m   1940\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:939\u001b[0m, in \u001b[0;36mDefaultDialect.do_executemany\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdo_executemany\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 939\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecutemany(statement, parameters)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mysql\\connector\\cursor_cext.py:470\u001b[0m, in \u001b[0;36mCMySQLCursor.executemany\u001b[1;34m(self, operation, seq_params)\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rowcount \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 470\u001b[0m stmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_insert(operation, seq_params)\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stmt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m stmt\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\mysql\\connector\\cursor_cext.py:424\u001b[0m, in \u001b[0;36mCMySQLCursor._batch_insert\u001b[1;34m(self, operation, seq_params)\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProgrammingError(\u001b[38;5;28mstr\u001b[39m(err)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 424\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InterfaceError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed executing the operation; \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInterfaceError\u001b[0m: (mysql.connector.errors.InterfaceError) Failed executing the operation; Python type list cannot be converted\n[SQL: INSERT INTO company_info_with_competitors (`Company_name`, `Symbol`, `Activity_Sphere`, `Tech_Subcategory`, `Core_Technology`, `Growth_Outlook`, `Market_Cap_Tier`, `Competitors`, `Competitor_List`) VALUES (%(Company_name)s, %(Symbol)s, %(Activity_Sphere)s, %(Tech_Subcategory)s, %(Core_Technology)s, %(Growth_Outlook)s, %(Market_Cap_Tier)s, %(Competitors)s, %(Competitor_List)s)]\n[parameters: [{'Company_name': 'Xperi', 'Symbol': 'XPER', 'Activity_Sphere': 'Consumer Tech, Media & Entertainment Licensing', 'Tech_Subcategory': 'Audio (DTS), Smart TV (TiVo OS), Automotive (DTS AutoStage), Semiconductor IP', 'Core_Technology': 'IP Licensing, Audio (DTS), Smart TV Platforms (TiVo), Automotive Media', 'Growth_Outlook': ' Cautious outlook (product-specific growth: TiVo OS & DTS AutoStage)', 'Market_Cap_Tier': 'Small-Cap', 'Competitors': 'Applied Materials, Lam Research, KLA, Entegris ', 'Competitor_List': ['Applied Materials', ' Lam Research', ' KLA', ' Entegris ']}, {'Company_name': 'X-FAB', 'Symbol': 'XFAB', 'Activity_Sphere': 'Semiconductor Foundry, Analog/Mixed-Signal ICs', 'Tech_Subcategory': 'CMOS, SOI, MEMS, SiC (Silicon Carbide), High-Voltage', 'Core_Technology': 'Wafer Fabrication, Specialty Foundry Services, Analog/Mixed-Signal Circuits', 'Growth_Outlook': 'Long-term growth (demand from automotive, industrial, and medical markets), with short-term headwinds', 'Market_Cap_Tier': 'Mid-Cap', 'Competitors': 'Tower Semiconductor, Littelfuse, GlobalFoundries, Analog Devices, STMicroelectronics, ON Semiconductor', 'Competitor_List': ['Tower Semiconductor', ' Littelfuse', ' GlobalFoundries', ' Analog Devices', ' STMicroelectronics', ' ON Semiconductor']}, {'Company_name': 'Wolfspeed', 'Symbol': 'WOLF', 'Activity_Sphere': 'Semiconductor Manufacturing, Power & RF Devices', 'Tech_Subcategory': 'Silicon Carbide (SiC), Gallium Nitride (GaN)', 'Core_Technology': 'Wide-bandgap semiconductors (SiC & GaN) for power devices and radio frequency (RF) applications.', 'Growth_Outlook': 'Long-term growth (demand from EV & renewable energy markets), with short-term headwinds', 'Market_Cap_Tier': 'Mid-Cap', 'Competitors': 'Infineon Technologies, ON Semiconductor, Rohm Co., Ltd., STMicroelectronics (in SiC segment); Qorvo, Inc., NXP Semiconductors (in RF segment)', 'Competitor_List': ['Infineon Technologies', ' ON Semiconductor', ' Rohm Co.', ' Ltd.', ' STMicroelectronics (in SiC segment); Qorvo', ' Inc.', ' NXP Semiconductors (in RF segment)']}, {'Company_name': 'WIN Semiconductors', 'Symbol': '3105.TWO', 'Activity_Sphere': 'Semiconductor Manufacturing, Specialty Foundry Services', 'Tech_Subcategory': 'GaAs (Gallium Arsenide), GaN (Gallium Nitride)', 'Core_Technology': 'Pure-play foundry services for GaAs and GaN wafers, focusing on RF and microwave applications.', 'Growth_Outlook': 'Long-term growth (demand from next-gen wireless, LEO satellites and IoT trends), with short-term headwinds', 'Market_Cap_Tier': 'Mid-Cap', 'Competitors': 'Global Communication Semiconductors (GCS Holdings), Advanced Wireless Semiconductor Co.', 'Competitor_List': ['Global Communication Semiconductors (GCS Holdings)', ' Advanced Wireless Semiconductor Co.']}, {'Company_name': 'Weebit Nano', 'Symbol': 'WBT', 'Activity_Sphere': 'Semiconductor Memory Technology, IP Licensing', 'Tech_Subcategory': 'Resistive RAM (ReRAM), Non-Volatile Memory (NVM)', 'Core_Technology': 'Next-generation, fab-friendly non-volatile memory (ReRAM) that is faster, more energy-efficient and scalable than traditional flash memory.', 'Growth_Outlook': 'Long-term growth (breakout phase driven by commercialization and partnerships in AI, automotive & IoT), with short-term headwinds (lack of significant revenue & profitability, and execution risk).', 'Market_Cap_Tier': 'Micro-Cap / Small-Cap', 'Competitors': '4DS Memory, BrainChip,  Phase Change Memory, MRAM.', 'Competitor_List': ['4DS Memory', ' BrainChip', '  Phase Change Memory', ' MRAM.']}, {'Company_name': 'Vishay Intertechnology', 'Symbol': 'VSH', 'Activity_Sphere': 'Semiconductor Manufacturing, Passive Electronic Components', 'Tech_Subcategory': 'Discrete semiconductors (MOSFETs, diodes, optoelectronics), passive components (resistors, capacitors, inductors)', 'Core_Technology': 'Manufacturing a broad range of discrete semiconductors and passive electronic components for mission-critical applications.', 'Growth_Outlook': 'Cautious outlook with long-term potential (expansion of manufacturing capacity, demand from EV, 5G, and renewable energy markets)', 'Market_Cap_Tier': 'Mid-Cap', 'Competitors': 'Infineon, ON Semiconductor, TDK-EPCOS, Murata, Yageo, Kyocera, Diodes Inc.', 'Competitor_List': ['Infineon', ' ON Semiconductor', ' TDK-EPCOS', ' Murata', ' Yageo', ' Kyocera', ' Diodes Inc.']}, {'Company_name': 'VisEra Technologies', 'Symbol': '6789', 'Activity_Sphere': 'Semiconductor Manufacturing, Foundry Services', 'Tech_Subcategory': 'Image Sensors, Optical Components, Wafer-Level Packaging (Color Filters, Micro-Lenses)', 'Core_Technology': 'Specialized foundry services for optical devices and sensors used in mobile phones, automotive, AR/VR, and other devices.', 'Growth_Outlook': 'Cautious outlook with long-term potential (demand for image sensors and optical components, especially in the mobile and automotive segments)', 'Market_Cap_Tier': 'Small-Cap', 'Competitors': 'Samsung, OmniVision, ', 'Competitor_List': ['Samsung', ' OmniVision', ' ']}, {'Company_name': 'VeriSilicon Microelectronics', 'Symbol': '688521', 'Activity_Sphere': 'Semiconductor Design IP & Custom Silicon Solutions', 'Tech_Subcategory': 'Processor IP (GPU, NPU, VPU), IoT Connectivity, Analog & Mixed-Signal IP', 'Core_Technology': 'A platform-based, comprehensive IP portfolio and custom turnkey silicon design services. VeriSilicon provides a one-stop-shop for customers to develop their own chips.', 'Growth_Outlook': 'Strong growth potential (rapid expansion of the global semiconductor IP market, particularly in AI, IoT, and automotive sectors)', 'Market_Cap_Tier': 'Mid-Cap', 'Competitors': 'ARM Holdings, Synopsys, Cadence Design Systems, Imagination Technologies, Ceva.', 'Competitor_List': ['ARM Holdings', ' Synopsys', ' Cadence Design Systems', ' Imagination Technologies', ' Ceva.']}  ... displaying 10 of 154 total bound parameter sets ...  {'Company_name': None, 'Symbol': None, 'Activity_Sphere': None, 'Tech_Subcategory': None, 'Core_Technology': None, 'Growth_Outlook': None, 'Market_Cap_Tier': None, 'Competitors': None, 'Competitor_List': None}, {'Company_name': None, 'Symbol': None, 'Activity_Sphere': None, 'Tech_Subcategory': None, 'Core_Technology': None, 'Growth_Outlook': None, 'Market_Cap_Tier': None, 'Competitors': None, 'Competitor_List': None}]]\n(Background on this error at: https://sqlalche.me/e/20/rvf5)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import mysql.connector\n",
    "import urllib.parse\n",
    "\n",
    "# 1. Завантажте ваш DataFrame, як ми робили раніше\n",
    "df_company_info = pd.read_csv('Company info (semi_conductor_se).csv', sep=';', quotechar='\"', encoding='cp1252')\n",
    "\n",
    "# 2. Створіть нову колонку з конкурентами\n",
    "df_company_info['Competitor_List'] = df_company_info['Competitors'].str.split(',')\n",
    "\n",
    "# 3. Налаштуйте підключення до MySQL\n",
    "user = 'root'\n",
    "password = 'UN4%39,h2r#k'\n",
    "host = 'localhost'\n",
    "database = 'ai_semiconductor'\n",
    "\n",
    "encoded_password = urllib.parse.quote_plus(password)\n",
    "engine = create_engine(f'mysql+mysqlconnector://{user}:{encoded_password}@{host}/{database}')\n",
    "\n",
    "# 4. Запишіть DataFrame в базу даних (якщо вона існує, вона буде замінена)\n",
    "df_company_info.to_sql('company_info_with_competitors', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Дані з колонкою 'Competitor_List' успішно завантажено в MySQL!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "905d1a04-926e-423e-9b44-695cad9853c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'ellipsis'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_company_info \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# ... Ваш код для створення Competitor_List ...\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Перетворюємо список у рядок, щоб SQL міг його зберегти\u001b[39;00m\n\u001b[0;32m      6\u001b[0m df_company_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompetitor_List_String\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_company_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompetitor_List\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    729\u001b[0m     path_or_buf,\n\u001b[0;32m    730\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    731\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    732\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    733\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    734\u001b[0m )\n\u001b[0;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:472\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    470\u001b[0m ):\n\u001b[0;32m    471\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file path or buffer object type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(filepath_or_buffer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[0;32m    475\u001b[0m     filepath_or_buffer\u001b[38;5;241m=\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    476\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    479\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    480\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'ellipsis'>"
     ]
    }
   ],
   "source": [
    " df_company_info = pd.read_csv(...)\n",
    "\n",
    "# ... Ваш код для створення Competitor_List ...\n",
    "\n",
    "# Перетворюємо список у рядок, щоб SQL міг його зберегти\n",
    "df_company_info['Competitor_List_String'] = df_company_info['Competitor_List'].apply(lambda x: ', '.join(x) if isinstance(x, list) else None)\n",
    "\n",
    "# Тепер записуємо оновлений DataFrame в базу даних, використовуючи нову колонку\n",
    "df_company_info.to_sql('company_info_with_competitors', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebbde694-cf6e-4159-968a-66f9de7774eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company_info = pd.read_csv(\n",
    "    'Company info (semi_conductor_se).csv',  # Замість '...' вкажіть назву вашого файлу\n",
    "    sep=';',\n",
    "    quotechar='\"',\n",
    "    encoding='cp1252'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3f96ed2-d3a9-4b07-9e77-e39c54bd4692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дані успішно завантажено в MySQL!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import mysql.connector\n",
    "import urllib.parse\n",
    "import re\n",
    "\n",
    "# 1. Завантаження та очищення даних\n",
    "# Завантажуємо ваш DataFrame, вказуючи роздільник, кодування та обробку лапок\n",
    "df_company_info = pd.read_csv('Company info (semi_conductor_se).csv', sep=';', quotechar='\"', encoding='cp1252')\n",
    "\n",
    "# 2. Обробка колонки 'Competitors'\n",
    "# Заповнюємо пропущені значення порожнім рядком, щоб уникнути помилок\n",
    "df_company_info['Competitors'] = df_company_info['Competitors'].fillna('')\n",
    "\n",
    "# Розділяємо рядок з конкурентами на список\n",
    "df_company_info['Competitor_List'] = df_company_info['Competitors'].str.split(',')\n",
    "\n",
    "# Перетворюємо список на рядок, щоб SQL міг його зберегти\n",
    "df_company_info['Competitor_List_String'] = df_company_info['Competitor_List'].apply(lambda x: ','.join([item.strip() for item in x]))\n",
    "df_company_info = df_company_info.drop(columns=['Competitor_List'])\n",
    "# 3. Налаштування підключення до MySQL\n",
    "user = 'root'\n",
    "password = 'UN4%39,h2r#k'\n",
    "host = 'localhost'\n",
    "database = 'ai_semiconductor'\n",
    "\n",
    "encoded_password = urllib.parse.quote_plus(password)\n",
    "engine = create_engine(f'mysql+mysqlconnector://{user}:{encoded_password}@{host}/{database}')\n",
    "\n",
    "# 4. Завантаження даних у MySQL\n",
    "df_company_info.to_sql('company_info_with_competitors', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Дані успішно завантажено в MySQL!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c12d0a97-e2ee-42c1-8cda-bce89005456e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Source               Target\n",
      "0                   Xperi    Applied Materials\n",
      "1                   X-FAB  Tower Semiconductor\n",
      "2  Vishay Intertechnology             Infineon\n",
      "3     VisEra Technologies              Samsung\n",
      "4                   Veeco              Aixtron\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93 entries, 0 to 92\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Source  93 non-null     object\n",
      " 1   Target  93 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import mysql.connector\n",
    "import urllib.parse\n",
    "import re\n",
    "\n",
    "# Завантаження вашої основної таблиці з інформацією про конкурентів\n",
    "# Зверніть увагу: ми завантажуємо її після того, як вона була успішно збережена в MySQL\n",
    "# або з вашого останього очищеного файлу.\n",
    "# df_company_info = pd.read_csv(...)\n",
    "\n",
    "# Переконайтеся, що колонка зі списками конкурентів існує\n",
    "if 'Competitor_List' not in df_company_info.columns:\n",
    "    df_company_info['Competitor_List_String'] = df_company_info['Competitors'].str.split(',')\n",
    "\n",
    "# Отримання списку всіх унікальних компаній\n",
    "all_companies = set(df_company_info['Company_name'].unique())\n",
    "\n",
    "# Створення порожнього списку для зв'язків\n",
    "edges = []\n",
    "\n",
    "# Ітерація по кожному рядку в DataFrame\n",
    "for index, row in df_company_info.iterrows():\n",
    "    source_company = row['Company_name']\n",
    "    competitors = row['Competitor_List_String']\n",
    "\n",
    "    # Ітерація по списку конкурентів\n",
    "    for competitor in competitors:\n",
    "        # Перевірка, чи є конкурент також у нашому датасеті\n",
    "        if competitor in all_companies:\n",
    "            # Додаємо пару до списку\n",
    "            edges.append({'Source': source_company, 'Target': competitor})\n",
    "\n",
    "# Створення нового DataFrame зі списком зв'язків\n",
    "df_connections = pd.DataFrame(edges)\n",
    "\n",
    "# Перевірка результату\n",
    "print(df_connections.head())\n",
    "print(df_connections.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbb0cc7b-13fe-4be9-98b9-8cb3bc2df8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Запис у MySQL\n",
    "df_connections.to_sql('company_connections', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a23ed2ea-d03e-4ec4-ad5c-81bbd174e56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Річна волатильність акцій:\n",
      "date\n",
      "2024-03-27    7.334922\n",
      "2025-05-22    2.232356\n",
      "2016-09-29    2.168790\n",
      "2024-11-28    2.141027\n",
      "2025-04-09    1.869765\n",
      "                ...   \n",
      "2015-12-25    0.205923\n",
      "2016-06-09    0.204896\n",
      "2021-12-31    0.196064\n",
      "2018-01-01    0.000000\n",
      "2012-01-02         NaN\n",
      "Name: close, Length: 3537, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('cleaned_semi_conductor_se.csv')\n",
    "\n",
    "# Припустимо, ваш DataFrame називається 'df'\n",
    "# Якщо стовпець з датами не є індексом, зробіть його таким\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Розраховуємо щоденну прибутковість (Daily Return) для кожної компанії\n",
    "daily_returns = df.groupby('company_name')['close'].pct_change()\n",
    "\n",
    "# Розраховуємо річну волатильність, групуючи за індексом (level=0)\n",
    "volatility = daily_returns.groupby(level=0).std() * np.sqrt(252)\n",
    "\n",
    "# Виводимо результат\n",
    "print(\"Річна волатильність акцій:\")\n",
    "print(volatility.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3dbe365a-d5d0-401f-9112-44c5289e89f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('cleaned_semi_conductor_se.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c049933f-0bcd-4dee-afba-944f1a69309c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'company_name', 'stock_name', 'date', 'open', 'high',\n",
      "       'low', 'close', 'volume'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cbc5976-2fa1-432f-a389-d20207c5de58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 company_name stock_name        date      open      high  \\\n",
      "0           0       NVIDIA       NVDA  2012-01-03  0.327805  0.330097   \n",
      "1           1       NVIDIA       NVDA  2012-01-04  0.322074  0.326888   \n",
      "2           2       NVIDIA       NVDA  2012-01-05  0.323908  0.338808   \n",
      "3           3       NVIDIA       NVDA  2012-01-06  0.336974  0.337204   \n",
      "4           4       NVIDIA       NVDA  2012-01-09  0.333536  0.339725   \n",
      "\n",
      "        low     close     volume  \n",
      "0  0.321157  0.321845  468044000  \n",
      "1  0.319094  0.325513  347372000  \n",
      "2  0.322533  0.337204  563548000  \n",
      "3  0.329410  0.333307  533252000  \n",
      "4  0.331014  0.333307  508244000  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1433d8cc-eaee-4f8d-82ab-ef105a90b736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'company_name', 'stock_name', 'date', 'open', 'high', 'low', 'close', 'volume']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "524956db-b6d7-4655-b44c-2f1107de4b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('cleaned_semi_conductor_se.csv')\n",
    "df['Date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8d7c78c-b35c-4662-b2f3-ed182d726919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Річна волатильність акцій:\n",
      "0        NaN\n",
      "1        NaN\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        NaN\n",
      "          ..\n",
      "422724   NaN\n",
      "422725   NaN\n",
      "422726   NaN\n",
      "422727   NaN\n",
      "422728   NaN\n",
      "Name: close, Length: 422729, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "daily_returns = df.groupby('company_name')['close'].pct_change()\n",
    "\n",
    "# Розраховуємо волатильність, групуючи за індексом (level=0)\n",
    "volatility = daily_returns.groupby(level=0).std() * np.sqrt(252)\n",
    "\n",
    "# Виводимо результат\n",
    "print(\"Річна волатильність акцій:\")\n",
    "print(volatility.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42ae3146-153f-4c22-a292-0538c90c875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns = df.groupby('company_name')['close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8866214e-a2c0-473e-9def-12d05b209e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Річна волатильність акцій:\n",
      "company_name\n",
      "GCT Semiconductor        3.117195\n",
      "SEALSQ                   2.000272\n",
      "Aeluma                   1.256393\n",
      "Navitas Semiconductor    1.255732\n",
      "BrainChip                1.113933\n",
      "                           ...   \n",
      "Analog Devices           0.300251\n",
      "Synopsys                 0.281826\n",
      "Lite-On Technology       0.280906\n",
      "Texas Instruments        0.280717\n",
      "Samsung                  0.265765\n",
      "Name: Daily_Return, Length: 152, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Припустимо, ви завантажили свій DataFrame\n",
    "# df = pd.read_csv('cleaned_semi_conductor_se.csv')\n",
    "# df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Розраховуємо щоденну прибутковість для кожної компанії,\n",
    "# групуючи за Company_name перед pct_change()\n",
    "df['Daily_Return'] = df.groupby('company_name')['close'].pct_change()\n",
    "\n",
    "# Тепер розраховуємо волатильність на основі Daily_Return,\n",
    "# знову групуючи за компанією\n",
    "volatility = df.groupby('company_name')['Daily_Return'].std() * np.sqrt(252)\n",
    "\n",
    "# Виводимо результат\n",
    "print(\"Річна волатильність акцій:\")\n",
    "print(volatility.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b96c9830-1e0e-47f3-861f-4e925dcbe514",
   "metadata": {},
   "outputs": [],
   "source": [
    "volatility.to_csv('volatility_by_company.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47089e6e-43f7-4c12-a42f-7ebc2ac811b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.ipynb_checkpoints',\n",
       " 'Ai semiconductor.ipynb',\n",
       " 'anaconda_projects',\n",
       " 'cleaned_semi_conductor_se.csv',\n",
       " 'Company info (semi_conductor_se).csv',\n",
       " 'README.md',\n",
       " 'semiconductor_stocks.db',\n",
       " 'semi_conductor_se.csv',\n",
       " 'volatility_by_company.csv']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8bef9977-12b1-4220-9999-cb59f73b7e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кластеризацію завершено. Результати збережено у файл 'volatility_clusters.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anzy\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Завантажуємо ваш DataFrame та обчислюємо щоденну прибутковість\n",
    "df = pd.read_csv('cleaned_semi_conductor_se.csv')\n",
    "df['Daily_Return'] = df.groupby('company_name')['close'].pct_change()\n",
    "\n",
    "# Підготовка даних для кластеризації\n",
    "# Ми перетворюємо дані, щоб кожна колонка була компанією, а рядки — датами\n",
    "data_for_clustering = df.pivot_table(\n",
    "    index='date',\n",
    "    columns='company_name',\n",
    "    values='Daily_Return'\n",
    ").fillna(0)\n",
    "\n",
    "# Транспонуємо дані, щоб кластеризувати компанії (рядки), а не дати (стовпці)\n",
    "data_for_clustering_T = data_for_clustering.T.fillna(0) # .T транспонує, fillna обробляє пропуски\n",
    "\n",
    "# Масштабування даних\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data_for_clustering_T)\n",
    "\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "kmeans = KMeans(n_clusters=4, random_state=0, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Створюємо DataFrame з результатами кластеризації\n",
    "clusters = pd.DataFrame(\n",
    "    {'company_name': data_for_clustering_T.index,\n",
    "     'Cluster_ID': cluster_labels}\n",
    ")\n",
    "\n",
    "# ... Ваш код для збереження файлу ...\n",
    "# Зберігаємо результати у файл для Power BI\n",
    "clusters.to_csv('volatility_clusters.csv', index=False)\n",
    "print(\"Кластеризацію завершено. Результати збережено у файл 'volatility_clusters.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80306cff-4d3e-4c53-8fb0-2d2817ca7405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "3536\n"
     ]
    }
   ],
   "source": [
    "print(len(data_for_clustering.columns))\n",
    "print(len(cluster_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd752aba-f30e-4525-a11c-60cf98124a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       company_name  Total Volume  Volume Rank\n",
      "0                                      ACM Research    1781936400         91.0\n",
      "1                                               AMD  169691908000          3.0\n",
      "2                                              AMEC   10100493232         43.0\n",
      "3                                         ASE Group    9426561029         49.0\n",
      "4                                 ASM International     823678426        115.0\n",
      "5                                              ASML    3803087183         75.0\n",
      "6                  ASMPT\\n (ASM Pacific Technology)    4837376309         67.0\n",
      "7  AT&amp;S Austria Technologie &amp; Systemtechnik     286959398        135.0\n",
      "8                                           AXT Inc    1170340900        109.0\n",
      "9                                         Advantest   39427472200         12.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Завантажуємо ваш основний датасет\n",
    "df_main = pd.read_csv('cleaned_semi_conductor_se.csv')\n",
    "\n",
    "# Групуємо за назвою компанії та рахуємо загальний обсяг\n",
    "total_volume = df_main.groupby('company_name')['volume'].sum().reset_index()\n",
    "total_volume.columns = ['company_name', 'Total Volume']\n",
    "\n",
    "# Розраховуємо ранг\n",
    "# 'dense' присвоює однаковий ранг компаніям з однаковим обсягом\n",
    "total_volume['Volume Rank'] = total_volume['Total Volume'].rank(method='dense', ascending=False)\n",
    "\n",
    "# Перевіряємо перші 10 рядків\n",
    "print(total_volume.head(10))\n",
    "\n",
    "# Зберігаємо результат у новий файл для Power BI\n",
    "total_volume.to_csv('company_volume_rank.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9fd91f89-3661-490d-bbdf-d0236695b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Замініть 'ваш_файл.csv' на назву вашого файлу\n",
    "df = pd.read_csv('company_volume_rank.csv')\n",
    "\n",
    "# Видаляємо всі нечислові символи з колонки\n",
    "# Це найефективніший спосіб очищення\n",
    "df['Volume Rank'] = df['Volume Rank'].astype(str).str.replace(r'[^0-9.]', '', regex=True)\n",
    "\n",
    "# Перетворюємо колонку в числовий тип.\n",
    "# errors='coerce' перетворить будь-яку помилку на NaN\n",
    "df['Volume Rank'] = pd.to_numeric(df['Volume Rank'], errors='coerce')\n",
    "\n",
    "# Заповнюємо порожні значення (NaN) нулями, якщо вони з'явилися\n",
    "df['Volume Rank'] = df['Volume Rank'].fillna(0).astype(int)\n",
    "\n",
    "# Зберігаємо новий файл, який буде ідеально працювати в Power BI\n",
    "df.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad46141b-f4bb-43d3-b1b0-445b307d40c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
